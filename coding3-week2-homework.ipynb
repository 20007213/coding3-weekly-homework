{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8a_TDA0eOtn"
   },
   "source": [
    "# Intro to simple text classification in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iX-_2g9yeOtp"
   },
   "outputs": [],
   "source": [
    "# Do our imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential #base keras model\n",
    "from keras.layers import Dense, Activation #dense = fully connected layer\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zRW0av17eOtt"
   },
   "outputs": [],
   "source": [
    "#if any of these give you problems, make sure you've installed all libraries used (pandas, sklearn, and matplot lib)\n",
    "# using conda install or pip install\n",
    "# see the moodle page \"Instructions for setting up and using Python and Jupyter\" for more info on how to do this\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import _stop_words\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cosine\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwhcWbk_eOtt"
   },
   "source": [
    "## Loading a dataset\n",
    "\n",
    "We're going to use a small set of 1000 movie reviews from IMDB. [The original dataset can be found here.](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews?resource=download) \n",
    "\n",
    "Here's how to load in the dataset into the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KM6fXWZafsod"
   },
   "outputs": [],
   "source": [
    "# This assumes the IMDBsubset.csv file lives in a directory called \"data\" which lives in the same directory as this notebook.\n",
    "# ***if you want to edit this notebook to use a different dataset, edit this to specify a different file:\n",
    "df = pd.read_csv(\"data/IMDBsubset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've got the data read in! We've used a special data type called a \"data frame\", using the Pandas library, to store this data. Pandas makes working with data pretty convenient.\n",
    "\n",
    "Printing df will show you the data in a table-like format (specifically, it'll show you the first and last few rows of the table).\n",
    "\n",
    "**Note that a sentiment of \"1\" means \"positive\" and \"0\" means \"negative\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Nothing is sacred. Just ask Ernie Fosselius. T...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>I hated it. I hate self-aware pretentious inan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>I usually try to be professional and construct...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>If you like me is going to see this in a film ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>This is like a zoology textbook, given that it...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review  sentiment\n",
       "0    One of the other reviewers has mentioned that ...          1\n",
       "1    A wonderful little production. <br /><br />The...          1\n",
       "2    I thought this was a wonderful way to spend ti...          1\n",
       "3    Basically there's a family where a little boy ...          0\n",
       "4    Petter Mattei's \"Love in the Time of Money\" is...          1\n",
       "..                                                 ...        ...\n",
       "995  Nothing is sacred. Just ask Ernie Fosselius. T...          1\n",
       "996  I hated it. I hate self-aware pretentious inan...          0\n",
       "997  I usually try to be professional and construct...          0\n",
       "998  If you like me is going to see this in a film ...          0\n",
       "999  This is like a zoology textbook, given that it...          0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is great, but if we want to read the full reviews (handy for later) then we can change our display options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.&lt;br /&gt;&lt;br /&gt;The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.&lt;br /&gt;&lt;br /&gt;It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.&lt;br /&gt;&lt;br /&gt;I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. &lt;br /&gt;&lt;br /&gt;The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. &lt;br /&gt;&lt;br /&gt;The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.&lt;br /&gt;&lt;br /&gt;This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.&lt;br /&gt;&lt;br /&gt;This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet &amp; his parents are fighting all the time.&lt;br /&gt;&lt;br /&gt;This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.&lt;br /&gt;&lt;br /&gt;OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing &amp; arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.&lt;br /&gt;&lt;br /&gt;3 out of 10 just for the well playing parents &amp; descent dialogs. As for the shots with Jake: just ignore them.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. &lt;br /&gt;&lt;br /&gt;This being a variation on the Arthur Schnitzler's play about the same theme, the director transfers the action to the present time New York where all these different characters meet and connect. Each one is connected in one way, or another to the next person, but no one seems to know the previous point of contact. Stylishly, the film has a sophisticated luxurious look. We are taken to see how these people live and the world they live in their own habitat.&lt;br /&gt;&lt;br /&gt;The only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits. A big city is not exactly the best place in which human relations find sincere fulfillment, as one discerns is the case with most of the people we encounter.&lt;br /&gt;&lt;br /&gt;The acting is good under Mr. Mattei's direction. Steve Buscemi, Rosario Dawson, Carol Kane, Michael Imperioli, Adrian Grenier, and the rest of the talented cast, make these characters come alive.&lt;br /&gt;&lt;br /&gt;We wish Mr. Mattei good luck and await anxiously for his next work.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Nothing is sacred. Just ask Ernie Fosselius. These days, everybody has a video camera, and a movie is hardly out before the spoofs start flying, quickly written and shot, and often posted directly to the internet. Spoofs are hot these days, and we go out of our way to make sure filmmakers don't get off on their own self-importance. 25 years ago, when the first Star Wars was made, it was a different world. Filmmaking was the playground of a select few and spoofs were very rare. Then God gave us Hardware Wars. It was shot to look cheap (or was it just cheap?) and the audio was obviously recorded after the fact. Does that take away from the experience? HECK NO! That's what makes it so great! It was raw and unpolished, and hit relentlessly on some of the more pretentious moments of the original movie. From Fluke Starbucker waving around a flashlight instead of a lightsaber (I did that when I was young!) to Chewchilla the Wookie Monster, to Auggie Ben Doggie's \"nah, just a little headache\" remark, this film short is as much a part of the phenomenon as any of the actual Star Wars films. Rent it. Buy it. Borrow it from a friend. And may the Farce be with you. Always.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>I hated it. I hate self-aware pretentious inanity that masquerades as art. This film is either stupidly inane or inanely stupid. After the first half hour, I fastfowarded through the DVD version, and saw the same juvenile shennanigans over and over and over. I became angered that I had spent hard-earned money for sophomoric clap-trap. Tinting drivel in sepia or blue does not make something a movie, let alone art.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>I usually try to be professional and constructive when I criticize movies, but my GOD!!! This was THE worst movie I have ever seen. Bad acting, bad effects, bad script, bad everything! &lt;br /&gt;&lt;br /&gt;The plot follows a group of teen cliche's on their way to a rave (that takes place in broad daylight) at a remote island. However, when the group arrives, all they find is an empty dance floor and bloody clothes. Determined to find out what happened to the rest of the party-goers, the clan set's off on a mission through a zombie-infested forest. During this crusade, they are aided by a police chick and a sea captain that just happens to have the right number of weapons to give to each of the kids. They also meet up with Jonathan Cherry and some other survivors. Basically the rest of the movie is a collection of poorly directed action sequences including a far too long shootout outside of the \"house of the dead.\" This fight came complete with cheesy Hollywood violence, redundant clips from the HOTD video game, and sloppy matrix-esque camera rotations. One of the character's even volunteers to sacrifice himself to save the others. Why? Not because he was noble and brave, but because part of his face got scarred by acid a zombie spat on him after he continued to beat the creature long after it had been disabled! I'm supposed to feel sorry for this guy?!?&lt;br /&gt;&lt;br /&gt;To sum it all up, there is absolutely no point in seeing this movie unless you want to see for yourself just how terrible it is. The theater I was in was more dead than the zombies on the screen, and I'm sure the money I wasted seeing this piece of sh*t could easily cover the costs it took to make it. GRADE: F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>If you like me is going to see this in a film history class or something like that at your school, try to convince your teacher to see something else. believe me, anything is better than this movie. it is slow paced, confusing, boring, poorly constructed, gory, gringy, do I need to go on? It's message is good, but I have seen them been handled better in several other films. The acting isn't even any good. This movie is just even more awkward, as it start off as being funny (not intensional though)because of it's surreal story, than at the end, just becomes uncomfortable to watch.&lt;br /&gt;&lt;br /&gt;I honestly feel like 1 hour and 40 minutes of my life has been robbed. Why would anyone want to watch a girls describe a threesome for 10 minutes, than watch them drive through a traffic jam for 20 minutes, listen to a hippie who can make sheep appear, witness a sort of rape, than see the female lead role eat her husband.&lt;br /&gt;&lt;br /&gt;Honestly this movie deserves nothing but a 1/10. And if your not happy with my preview,seriously I'm an open minded guy and I like movies that protest through symbolism, but this movie was just awful. make any excuse you can, to avoid this film.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>This is like a zoology textbook, given that its depiction of animals is so accurate. However, here are a few details that appear to have been slightly modified during the transition to film:&lt;br /&gt;&lt;br /&gt;- Handgun bullets never hit giant Komodo dragons. It doesn't matter how many times you shoot at the Komodo, bullets just won't go near it.&lt;br /&gt;&lt;br /&gt;- The best way to avoid being eaten by a giant Cobra, or a giant Komodo dragon, is just to stand there. The exception to this rule is if you've been told to stay very still, in which case you should run off, until the Komodo is right next to you, and then you should stand there, expecting defeat.&lt;br /&gt;&lt;br /&gt;- Minutes of choppy slow motion footage behind the credits really makes for enjoyable watching.&lt;br /&gt;&lt;br /&gt;- $5,000 is a memory enhancement tool, and an ample substitute for losing your boating license/getting arrested.&lt;br /&gt;&lt;br /&gt;- Members of elite army units don't see giant Komodo dragons coming until they are within one metre of the over-sized beings. Maybe the computer-generated nature of these dragons has something to do with it.&lt;br /&gt;&lt;br /&gt;- When filming a news story aiming on exposing illegal animal testing, a reporter and a cameraman with one camera is all the gear and personnel you will need; sound gear, a second camera, microphones etc are all superfluous.&lt;br /&gt;&lt;br /&gt;- When you hear a loud animal scream, and one person has a gun, he should take it out and point it at the nearest person.&lt;br /&gt;&lt;br /&gt;- When you take a gun out, the sound of the safety being taken off will be made, even if your finger is nowhere near the safety&lt;br /&gt;&lt;br /&gt;- Reporters agree to go half-way around the world in order to expose something - without having the faintest idea what they're exposing. Background research and vague knowledge are out of fashion in modern journalism.&lt;br /&gt;&lt;br /&gt;- Handguns hold at least 52 bullets in one clip, and then more than that in the next clip. Despite that, those with guns claim that they will need more ammo.&lt;br /&gt;&lt;br /&gt;- Expensive cameras (also, remember that the reporter only has one camera) are regularly left behind without even a moment's hesitation or regret. These cameras amazingly manage to make their way back to the reporter all by themselves.&lt;br /&gt;&lt;br /&gt;- The blonde girl really is the stupid one.&lt;br /&gt;&lt;br /&gt;- The same girl that says not to go into a house because a Komodo dragon can easily run right through it, thus making it unsafe, takes a team into a building made of the same material for protection - and nobody says a word about it.&lt;br /&gt;&lt;br /&gt;- High-tech facilities look like simple offices with high school chemistry sets.&lt;br /&gt;&lt;br /&gt;- Genetically-modified snakes grow from normal size to 100 feet long in a matter of a day, but don't grow at all in the weeks either side.&lt;br /&gt;&lt;br /&gt;- The military routinely destroys entire islands when people don't meet contact deadlines.&lt;br /&gt;&lt;br /&gt;- Men with guns don't necessarily change the direction they're shooting when their target is no longer right in front of them. Instead, they just keep shooting into the air.&lt;br /&gt;&lt;br /&gt;- The better looking you are, the greater your chance of surviving giant creatures.&lt;br /&gt;&lt;br /&gt;- Women's intuition is reliable enough to change even the most stubborn of minds.&lt;br /&gt;&lt;br /&gt;- Any time you're being hunted by giant creatures is a great time to hit on girls half your age.&lt;br /&gt;&lt;br /&gt;- Animal noises are an appropriate masking noise for 'swearing' at the same volume.&lt;br /&gt;&lt;br /&gt;- Old Israeli and Russian planes are regularly used by the US Military.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  review  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.<br /><br />This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. <br /><br />This being a variation on the Arthur Schnitzler's play about the same theme, the director transfers the action to the present time New York where all these different characters meet and connect. Each one is connected in one way, or another to the next person, but no one seems to know the previous point of contact. Stylishly, the film has a sophisticated luxurious look. We are taken to see how these people live and the world they live in their own habitat.<br /><br />The only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits. A big city is not exactly the best place in which human relations find sincere fulfillment, as one discerns is the case with most of the people we encounter.<br /><br />The acting is good under Mr. Mattei's direction. Steve Buscemi, Rosario Dawson, Carol Kane, Michael Imperioli, Adrian Grenier, and the rest of the talented cast, make these characters come alive.<br /><br />We wish Mr. Mattei good luck and await anxiously for his next work.   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ...   \n",
       "995                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Nothing is sacred. Just ask Ernie Fosselius. These days, everybody has a video camera, and a movie is hardly out before the spoofs start flying, quickly written and shot, and often posted directly to the internet. Spoofs are hot these days, and we go out of our way to make sure filmmakers don't get off on their own self-importance. 25 years ago, when the first Star Wars was made, it was a different world. Filmmaking was the playground of a select few and spoofs were very rare. Then God gave us Hardware Wars. It was shot to look cheap (or was it just cheap?) and the audio was obviously recorded after the fact. Does that take away from the experience? HECK NO! That's what makes it so great! It was raw and unpolished, and hit relentlessly on some of the more pretentious moments of the original movie. From Fluke Starbucker waving around a flashlight instead of a lightsaber (I did that when I was young!) to Chewchilla the Wookie Monster, to Auggie Ben Doggie's \"nah, just a little headache\" remark, this film short is as much a part of the phenomenon as any of the actual Star Wars films. Rent it. Buy it. Borrow it from a friend. And may the Farce be with you. Always.   \n",
       "996                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     I hated it. I hate self-aware pretentious inanity that masquerades as art. This film is either stupidly inane or inanely stupid. After the first half hour, I fastfowarded through the DVD version, and saw the same juvenile shennanigans over and over and over. I became angered that I had spent hard-earned money for sophomoric clap-trap. Tinting drivel in sepia or blue does not make something a movie, let alone art.   \n",
       "997                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            I usually try to be professional and constructive when I criticize movies, but my GOD!!! This was THE worst movie I have ever seen. Bad acting, bad effects, bad script, bad everything! <br /><br />The plot follows a group of teen cliche's on their way to a rave (that takes place in broad daylight) at a remote island. However, when the group arrives, all they find is an empty dance floor and bloody clothes. Determined to find out what happened to the rest of the party-goers, the clan set's off on a mission through a zombie-infested forest. During this crusade, they are aided by a police chick and a sea captain that just happens to have the right number of weapons to give to each of the kids. They also meet up with Jonathan Cherry and some other survivors. Basically the rest of the movie is a collection of poorly directed action sequences including a far too long shootout outside of the \"house of the dead.\" This fight came complete with cheesy Hollywood violence, redundant clips from the HOTD video game, and sloppy matrix-esque camera rotations. One of the character's even volunteers to sacrifice himself to save the others. Why? Not because he was noble and brave, but because part of his face got scarred by acid a zombie spat on him after he continued to beat the creature long after it had been disabled! I'm supposed to feel sorry for this guy?!?<br /><br />To sum it all up, there is absolutely no point in seeing this movie unless you want to see for yourself just how terrible it is. The theater I was in was more dead than the zombies on the screen, and I'm sure the money I wasted seeing this piece of sh*t could easily cover the costs it took to make it. GRADE: F   \n",
       "998                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           If you like me is going to see this in a film history class or something like that at your school, try to convince your teacher to see something else. believe me, anything is better than this movie. it is slow paced, confusing, boring, poorly constructed, gory, gringy, do I need to go on? It's message is good, but I have seen them been handled better in several other films. The acting isn't even any good. This movie is just even more awkward, as it start off as being funny (not intensional though)because of it's surreal story, than at the end, just becomes uncomfortable to watch.<br /><br />I honestly feel like 1 hour and 40 minutes of my life has been robbed. Why would anyone want to watch a girls describe a threesome for 10 minutes, than watch them drive through a traffic jam for 20 minutes, listen to a hippie who can make sheep appear, witness a sort of rape, than see the female lead role eat her husband.<br /><br />Honestly this movie deserves nothing but a 1/10. And if your not happy with my preview,seriously I'm an open minded guy and I like movies that protest through symbolism, but this movie was just awful. make any excuse you can, to avoid this film.   \n",
       "999  This is like a zoology textbook, given that its depiction of animals is so accurate. However, here are a few details that appear to have been slightly modified during the transition to film:<br /><br />- Handgun bullets never hit giant Komodo dragons. It doesn't matter how many times you shoot at the Komodo, bullets just won't go near it.<br /><br />- The best way to avoid being eaten by a giant Cobra, or a giant Komodo dragon, is just to stand there. The exception to this rule is if you've been told to stay very still, in which case you should run off, until the Komodo is right next to you, and then you should stand there, expecting defeat.<br /><br />- Minutes of choppy slow motion footage behind the credits really makes for enjoyable watching.<br /><br />- $5,000 is a memory enhancement tool, and an ample substitute for losing your boating license/getting arrested.<br /><br />- Members of elite army units don't see giant Komodo dragons coming until they are within one metre of the over-sized beings. Maybe the computer-generated nature of these dragons has something to do with it.<br /><br />- When filming a news story aiming on exposing illegal animal testing, a reporter and a cameraman with one camera is all the gear and personnel you will need; sound gear, a second camera, microphones etc are all superfluous.<br /><br />- When you hear a loud animal scream, and one person has a gun, he should take it out and point it at the nearest person.<br /><br />- When you take a gun out, the sound of the safety being taken off will be made, even if your finger is nowhere near the safety<br /><br />- Reporters agree to go half-way around the world in order to expose something - without having the faintest idea what they're exposing. Background research and vague knowledge are out of fashion in modern journalism.<br /><br />- Handguns hold at least 52 bullets in one clip, and then more than that in the next clip. Despite that, those with guns claim that they will need more ammo.<br /><br />- Expensive cameras (also, remember that the reporter only has one camera) are regularly left behind without even a moment's hesitation or regret. These cameras amazingly manage to make their way back to the reporter all by themselves.<br /><br />- The blonde girl really is the stupid one.<br /><br />- The same girl that says not to go into a house because a Komodo dragon can easily run right through it, thus making it unsafe, takes a team into a building made of the same material for protection - and nobody says a word about it.<br /><br />- High-tech facilities look like simple offices with high school chemistry sets.<br /><br />- Genetically-modified snakes grow from normal size to 100 feet long in a matter of a day, but don't grow at all in the weeks either side.<br /><br />- The military routinely destroys entire islands when people don't meet contact deadlines.<br /><br />- Men with guns don't necessarily change the direction they're shooting when their target is no longer right in front of them. Instead, they just keep shooting into the air.<br /><br />- The better looking you are, the greater your chance of surviving giant creatures.<br /><br />- Women's intuition is reliable enough to change even the most stubborn of minds.<br /><br />- Any time you're being hunted by giant creatures is a great time to hit on girls half your age.<br /><br />- Animal noises are an appropriate masking noise for 'swearing' at the same volume.<br /><br />- Old Israeli and Russian planes are regularly used by the US Military.   \n",
       "\n",
       "     sentiment  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            0  \n",
       "4            1  \n",
       "..         ...  \n",
       "995          1  \n",
       "996          0  \n",
       "997          0  \n",
       "998          0  \n",
       "999          0  \n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None) #show me everything in the column, even if it's long!\n",
    "df #Show me the first and last few examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do something super simple to transform this into a dataset that we can send to a neural network. \n",
    "\n",
    "Similarly to the sentiment classification we discussed in lecture last week, we're going to represent each example (review) as a vector of word counts.\n",
    "\n",
    "The CountVectorizer object from sklearn allows us to make these word count vectors pretty easily. Once we do the counts, we'll store these in a new dataframe.\n",
    "\n",
    "\n",
    "The following code transforms a review dataframe to a word count dataframe called wordcounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform a dataframe containing a column named \"review\" \n",
    "# such that each row becomes represented by a set of word counts, corresponding to the number of each term in the review\n",
    "\n",
    "#These next two lines perform word counting:\n",
    "vectorizer = CountVectorizer(stop_words='english', min_df=0.01)\n",
    "#stop_words='english' removes very common english words that are unlikely to be useful (e.g. \"and\", \"the\")\n",
    "#min_df=0.1 removes very rare words that are likely to be typos, uninformative, etc.\n",
    "# You can type ?CountVectorizer in its own cell to read its documentation\n",
    "#***Note that \"df['review']\" is used below because \"review\" is the name of the column containing our text in the dataframe\n",
    "#If you apply this to your own data, you may probably need to change this column name!\n",
    "matrix = vectorizer.fit_transform(df['review'])\n",
    "    \n",
    "#This line converts matrix into another dataframe, with column names corresponding to the word being counted\n",
    "data = pd.DataFrame(matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>20</th>\n",
       "      <th>25</th>\n",
       "      <th>30</th>\n",
       "      <th>50</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youth</th>\n",
       "      <th>zero</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1673 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     000  10  100  12  13  15  20  25  30  50  ...  year  years  yes  york  \\\n",
       "0      0   0    0   0   0   0   0   0   0   0  ...     0      0    0     0   \n",
       "1      0   0    0   0   0   0   0   0   0   0  ...     0      0    0     0   \n",
       "2      0   0    0   0   0   0   0   0   0   0  ...     0      1    0     0   \n",
       "3      0   1    0   0   0   0   0   0   0   0  ...     0      0    0     0   \n",
       "4      0   0    0   0   0   0   0   0   0   0  ...     0      0    0     1   \n",
       "..   ...  ..  ...  ..  ..  ..  ..  ..  ..  ..  ...   ...    ...  ...   ...   \n",
       "995    0   0    0   0   0   0   0   1   0   0  ...     0      1    0     0   \n",
       "996    0   0    0   0   0   0   0   0   0   0  ...     0      0    0     0   \n",
       "997    0   0    0   0   0   0   0   0   0   0  ...     0      0    0     0   \n",
       "998    0   2    0   0   0   0   1   0   0   0  ...     0      0    0     0   \n",
       "999    1   0    1   0   0   0   0   0   0   0  ...     0      0    0     0   \n",
       "\n",
       "     young  younger  youth  zero  zombie  zombies  \n",
       "0        0        0      0     0       0        0  \n",
       "1        0        0      0     0       0        0  \n",
       "2        1        0      0     0       0        0  \n",
       "3        0        0      0     0       2        0  \n",
       "4        0        0      0     0       0        0  \n",
       "..     ...      ...    ...   ...     ...      ...  \n",
       "995      1        0      0     0       0        0  \n",
       "996      0        0      0     0       0        0  \n",
       "997      0        0      0     0       2        1  \n",
       "998      0        0      0     0       0        0  \n",
       "999      0        0      0     0       0        0  \n",
       "\n",
       "[1000 rows x 1673 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data #prints data to screen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can examine this dataset, e.g. to look at the column of counts for the word \"wonderful\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      1\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "995    0\n",
       "996    0\n",
       "997    0\n",
       "998    0\n",
       "999    0\n",
       "Name: wonderful, Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"wonderful\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "995    0\n",
       "996    1\n",
       "997    0\n",
       "998    0\n",
       "999    0\n",
       "Name: hate, Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#or the word hate:\n",
    "data[\"hate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do some machine learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, let's split our dataset into training and test sets\n",
    "# Remember: X is for input, y is for output\n",
    "# The first argument of train_test_split is your training data (here, lives in \"data\" object you created using word counts)\n",
    "# The second argument of train_test_split is your labels/targets for the training data. This lives in the \"sentiment\" column of the original dataframe df we loaded from the file.\n",
    "# (***If you are using a different dataset, you'll need to change the name of this column to whatever it is in your dataset)\n",
    "# The test_size argument specifies % of data going into test set: here, 20% of the data goes into test set and 80% goes into training set\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, df['sentiment'], test_size=0.2, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you ever want to learn more about a function, you can always use ? \n",
    "?train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ykvGqf40eOtu",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 1673)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can examine it a bit using np.shape:\n",
    "np.shape(X_train) #What does our training data look like? It's 800 rows, with 1674 dimensions of input (features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "hiLtJgDYeOtu"
   },
   "outputs": [],
   "source": [
    "#Now let's make a simple neural network with 1 hidden layer containing 10 neurons\n",
    "num_neurons = 10 # neurons in each layer\n",
    "model = Sequential()\n",
    "\n",
    "#Make the first (hidden) layer, which will have num_neurons neurons. Each neuron will get inputs from all columns of the dataframe, except sentiment\n",
    "#model.add(Dense(num_neurons, input_dim=len(data.columns)-1))\n",
    "model.add(Dense(num_neurons, input_dim=np.shape(X_train)[1]))\n",
    "model.add(Activation('sigmoid')) #Now we'll use a sigmoid activation function\n",
    "\n",
    "model.add(Dense(num_neurons, input_dim=10))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "#Now let's add another layer for the output: A single sigmoid neuron.\n",
    "model.add(Dense(1)) \n",
    "model.add(Activation('sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_13 (Dense)            (None, 10)                16740     \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,861\n",
      "Trainable params: 16,861\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "tcylQdKjeOtv"
   },
   "outputs": [],
   "source": [
    "#Use compile() to set up our training\n",
    "\n",
    "# For loss, we'll use binary cross-entropy loss, \n",
    "# which is appropriate for a binary classification problem (0/1 for negative/positive)\n",
    "# ***If you edit this notebook to apply it to a multi-class classification problem, you'll need \n",
    "#    to change the loss to something like categorical_crossentropy, and you'll also need to change the\n",
    "#    encoding of the class to a one hot representation (see https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/)\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "5O2u0WC2eOtv",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "23/25 [==========================>...] - ETA: 0s - loss: 0.7533 - accuracy: 0.5190"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 21:34:05.296851: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 11ms/step - loss: 0.7504 - accuracy: 0.5200 - val_loss: 0.7780 - val_accuracy: 0.4250\n",
      "Epoch 2/10\n",
      "12/25 [=============>................] - ETA: 0s - loss: 0.7322 - accuracy: 0.4792"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 21:34:05.552801: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7078 - accuracy: 0.5200 - val_loss: 0.7284 - val_accuracy: 0.4250\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.6863 - accuracy: 0.5200 - val_loss: 0.7066 - val_accuracy: 0.4250\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6699 - accuracy: 0.5200 - val_loss: 0.6888 - val_accuracy: 0.4250\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6482 - accuracy: 0.5763 - val_loss: 0.6710 - val_accuracy: 0.5300\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6220 - accuracy: 0.7925 - val_loss: 0.6491 - val_accuracy: 0.6550\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5899 - accuracy: 0.8625 - val_loss: 0.6282 - val_accuracy: 0.7200\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5539 - accuracy: 0.9175 - val_loss: 0.6057 - val_accuracy: 0.7650\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5138 - accuracy: 0.9287 - val_loss: 0.5846 - val_accuracy: 0.7750\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4729 - accuracy: 0.9425 - val_loss: 0.5646 - val_accuracy: 0.7650\n"
     ]
    }
   ],
   "source": [
    "#Train it!\n",
    "# Plus store history of training in a variable called \"history\"\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at how training set and test set accuracy change with each epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x298fa56d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='training set accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'test set accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining model behaviour\n",
    "\n",
    "First, let's explore how we can apply the trained model to a specific example in our test data (or training data), to examine what it's done.\n",
    "\n",
    "We'll use the following code techniques:\n",
    "* We can apply the trained model to any example using the `.predict()` function\n",
    "* We can get the nth row from any dataframe using the `.iloc[[n]]` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35659155]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For instance, let's make z the first test example:\n",
    "z = X_test.iloc[[0]]\n",
    "\n",
    "#and let's output the prediction for this example:\n",
    "model.predict(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this prediction will be somewhere between 0 and 1. This can be interpreted loosely as confidence: closer to 1 is more confident it is positive sentiment, closer to 0 is more confident it is negative sentiment.\n",
    "\n",
    "Let's compare this to the actual sentiment of the review, as stored in y_test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "993    0\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.iloc[[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sense of this, we probably also want to look at the actual text review, which doesn't live in X_test but does live in the original dataframe we loaded from the CSV file, i.e. `df`. Since our `train_test_split` function has randomised the order of the data before splitting into training and testing sets, we need to get the id (row number) for `df` corresponding to this first test example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "993    Tim Robbins and John Cusack are two actors I have appreciated throughout their careers, and that was the only reason for choosing to watch this movie. Well, all I can say is I totally regretted it! These two great actors humiliate themselves all the way through by performing a number of irrelevant, unimaginative and kitch to the extreme (not that this is bad on its own)sketches that are supposed to make people laugh, but fail to do so. The only reason I can think is that the director was their friend, and they decided to support his movie by starring in it-I can't think of anything else because this movie is SO cheap! Fortunately Tim Robbins and John Cusack haven't disappointed me ever since. I would recommend you to avoid this film, unless you want your opinion about the two actors spoiled.\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ids = list(X_test.index) #gets the original indices in the df dataframe\n",
    "#test_ids[n] now refers to the id number of the nth test example\n",
    "originalReview = df.iloc[[test_ids[0]]].review\n",
    "originalReview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try this with a few more examples and see what you find. If you're comfortable with python, can you think of a way to identify misclassified test examples and just print out those? Or, even better, find test examples that are confidently classified correctly, or test examples that are \"confidently\" misclassified, and examine those?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more fun, how about testing this classifier on our own new, fake \"reviews\"? Here's code to create an example of your own and apply the classifier to it. We'll have to first convert a string of text to a vector of word counts and put it in a dataframe, so here's a function for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turns a text string into a dataframe example (***Note you'll need to change this from 'review' for your own dataset)\n",
    "def createExample(myText):\n",
    "\n",
    "    newExample = np.array([[myText]])\n",
    "    tdf = pd.DataFrame(newExample, columns=[\"review\"])\n",
    "    matrix = vectorizer.transform(tdf['review'])\n",
    "    newDf = pd.DataFrame(matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "    return newDf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here's a text about zombies\n",
    "myText = \"This movie is about zombies zombies zombies\"\n",
    "t = createExample(myText) #When we print the dataframe, you see zombies' word count is 3:\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#apply the model to classify your new text:\n",
    "model.predict(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try writing some \"great\" and \"terrible\" reviews and see what happens to the classification outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(createExample(\"This movie is the worst it's terrible horrible\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore on your own\n",
    "\n",
    "Change the code above to explore:\n",
    "* Does changing the number of neurons in the hidden layer change the results? What happens to accuracy when you use 1 neuron? 100 neurons? \n",
    "* Try editing the neural network so that you have 2 hidden layers of 10 neurons each. What happens to accuracy? \n",
    "\n",
    "Investigating the model\n",
    "* Can you examine the model's performance on the test data to discover anything about what mistakes this model makes? Or anything about what types of reviews are easy to classify accurately?\n",
    "* Can you come up with your own, new examples of positive or negative reviews that illustrate the mistakes the model makes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This assumes the IMDBsubset.csv file lives in a directory called \"data\" which lives in the same directory as this notebook.\n",
    "# ***if you want to edit this notebook to use a different dataset, edit this to specify a different file:\n",
    "df = pd.read_csv(\"data/Tweets.csv\").dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>4eac33d1c0</td>\n",
       "      <td>wish we could come see u on Denver  husband lost his job and can`t afford it</td>\n",
       "      <td>d lost</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>4f4c4fc327</td>\n",
       "      <td>I`ve wondered about rake to.  The client has made it clear .NET only, don`t force devs to learn a new lang  #agile #ccnet</td>\n",
       "      <td>, don`t force</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>f67aae2310</td>\n",
       "      <td>Yay good for both of you. Enjoy the break - you probably need it after such hectic weekend  Take care hun xxxx</td>\n",
       "      <td>Yay good for both of you.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>ed167662a5</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>6f7127d9d7</td>\n",
       "      <td>All this flirting going on - The ATG smiles. Yay.  ((hugs))</td>\n",
       "      <td>All this flirting going on - The ATG smiles. Yay.  ((hugs)</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27480 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID  \\\n",
       "0      cb774db0d1   \n",
       "1      549e992a42   \n",
       "2      088c60f138   \n",
       "3      9642c003ef   \n",
       "4      358bd9e861   \n",
       "...           ...   \n",
       "27476  4eac33d1c0   \n",
       "27477  4f4c4fc327   \n",
       "27478  f67aae2310   \n",
       "27479  ed167662a5   \n",
       "27480  6f7127d9d7   \n",
       "\n",
       "                                                                                                                             text  \\\n",
       "0                                                                                             I`d have responded, if I were going   \n",
       "1                                                                                   Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                                                                                                       my boss is bullying me...   \n",
       "3                                                                                                  what interview! leave me alone   \n",
       "4                                                      Sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "...                                                                                                                           ...   \n",
       "27476                                                wish we could come see u on Denver  husband lost his job and can`t afford it   \n",
       "27477   I`ve wondered about rake to.  The client has made it clear .NET only, don`t force devs to learn a new lang  #agile #ccnet   \n",
       "27478              Yay good for both of you. Enjoy the break - you probably need it after such hectic weekend  Take care hun xxxx   \n",
       "27479                                                                                                  But it was worth it  ****.   \n",
       "27480                                                                 All this flirting going on - The ATG smiles. Yay.  ((hugs))   \n",
       "\n",
       "                                                    selected_text sentiment  \n",
       "0                             I`d have responded, if I were going   neutral  \n",
       "1                                                        Sooo SAD  negative  \n",
       "2                                                     bullying me  negative  \n",
       "3                                                  leave me alone  negative  \n",
       "4                                                   Sons of ****,  negative  \n",
       "...                                                           ...       ...  \n",
       "27476                                                      d lost  negative  \n",
       "27477                                               , don`t force  negative  \n",
       "27478                                   Yay good for both of you.  positive  \n",
       "27479                                  But it was worth it  ****.  positive  \n",
       "27480  All this flirting going on - The ATG smiles. Yay.  ((hugs)   neutral  \n",
       "\n",
       "[27480 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None) #show me everything in the column, even if it's long!\n",
    "df #Show me the first and last few examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform a dataframe containing a column named \"review\" \n",
    "# such that each row becomes represented by a set of word counts, corresponding to the number of each term in the review\n",
    "\n",
    "#These next two lines perform word counting:\n",
    "vectorizer = CountVectorizer(stop_words='english', min_df=0.001)\n",
    "#stop_words='english' removes very common english words that are unlikely to be useful (e.g. \"and\", \"the\")\n",
    "#min_df=0.1 removes very rare words that are likely to be typos, uninformative, etc.\n",
    "# You can type ?CountVectorizer in its own cell to read its documentation\n",
    "#***Note that \"df['review']\" is used below because \"review\" is the name of the column containing our text in the dataframe\n",
    "#If you apply this to your own data, you may probably need to change this column name!\n",
    "matrix = vectorizer.fit_transform(df['text'])\n",
    "\n",
    "#This line converts matrix into another dataframe, with column names corresponding to the word being counted\n",
    "data = pd.DataFrame(matrix.toarray(), columns=vectorizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                               I`d have responded, if I were going\n",
       "1                                                                                     Sooo SAD I will miss you here in San Diego!!!\n",
       "2                                                                                                         my boss is bullying me...\n",
       "3                                                                                                    what interview! leave me alone\n",
       "4                                                        Sons of ****, why couldn`t they put them on the releases we already bought\n",
       "                                                                    ...                                                            \n",
       "27476                                                  wish we could come see u on Denver  husband lost his job and can`t afford it\n",
       "27477     I`ve wondered about rake to.  The client has made it clear .NET only, don`t force devs to learn a new lang  #agile #ccnet\n",
       "27478                Yay good for both of you. Enjoy the break - you probably need it after such hectic weekend  Take care hun xxxx\n",
       "27479                                                                                                    But it was worth it  ****.\n",
       "27480                                                                   All this flirting going on - The ATG smiles. Yay.  ((hugs))\n",
       "Name: text, Length: 27480, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10', '100', '11', '12', '14', '15', '1st', '20', '24', '25',\n",
       "       '2day', '2nd', '30', '40', '4th', '50', 'able', 'absolutely',\n",
       "       'account', 'actually', 'add', 'afternoon', 'ages', 'ago', 'agree',\n",
       "       'ah', 'ahh', 'ahhh', 'aint', 'air', 'airport', 'album', 'alot',\n",
       "       'alright', 'amazing', 'annoying', 'answer', 'anymore', 'anytime',\n",
       "       'anyways', 'app', 'apparently', 'apple', 'appreciate', 'apps',\n",
       "       'aren', 'art', 'ask', 'asleep', 'ate', 'aw', 'awake', 'away',\n",
       "       'awesome', 'awful', 'aww', 'awww', 'babe', 'baby', 'bad', 'band',\n",
       "       'bank', 'bbq', 'bday', 'beach', 'beat', 'beautiful', 'bed', 'beer',\n",
       "       'believe', 'best', 'bet', 'better', 'bgt', 'big', 'bike',\n",
       "       'birthday', 'bit', 'black', 'blackberry', 'bless', 'blip', 'blog',\n",
       "       'bloody', 'blue', 'body', 'boo', 'book', 'books', 'bored',\n",
       "       'boring', 'bought', 'bout', 'boy', 'boyfriend', 'boys', 'break',\n",
       "       'breakfast', 'bring', 'bro', 'broke', 'broken', 'brother',\n",
       "       'brothers', 'btw', 'bummed', 'bummer', 'bus', 'business', 'busy',\n",
       "       'buy', 'bye', 'cake', 'called', 'came', 'camera', 'cancelled',\n",
       "       'car', 'card', 'care', 'case', 'cat', 'catch', 'cats', 'caught',\n",
       "       'cause', 'cd', 'chance', 'change', 'changed', 'chat', 'check',\n",
       "       'checked', 'cheese', 'chicken', 'chillin', 'chocolate', 'church',\n",
       "       'city', 'class', 'classes', 'clean', 'cleaning', 'close', 'closed',\n",
       "       'clothes', 'club', 'coffee', 'cold', 'college', 'com', 'come',\n",
       "       'comes', 'coming', 'comment', 'company', 'completely', 'computer',\n",
       "       'concert', 'congrats', 'congratulations', 'cool', 'copy', 'cos',\n",
       "       'couldn', 'count', 'couple', 'course', 'cousin', 'coz', 'crazy',\n",
       "       'cream', 'crying', 'cup', 'currently', 'cut', 'cute', 'cuz', 'da',\n",
       "       'dad', 'daddy', 'dance', 'dancing', 'dang', 'dark', 'date',\n",
       "       'daughter', 'david', 'day', 'days', 'dead', 'deal', 'dear',\n",
       "       'decided', 'definitely', 'did', 'didn', 'didnt', 'die', 'died',\n",
       "       'different', 'dinner', 'disappointed', 'dm', 'does', 'doesn',\n",
       "       'doesnt', 'dog', 'dogs', 'doing', 'don', 'dont', 'door', 'dream',\n",
       "       'dreams', 'dress', 'drink', 'drinking', 'drive', 'driving',\n",
       "       'drunk', 'dude', 'dunno', 'dvd', 'earlier', 'early', 'easy', 'eat',\n",
       "       'eating', 'eh', 'em', 'email', 'end', 'ended', 'english', 'enjoy',\n",
       "       'enjoyed', 'enjoying', 'episode', 'especially', 'evening',\n",
       "       'everybody', 'exactly', 'exam', 'exams', 'excited', 'exciting',\n",
       "       'extra', 'eye', 'eyes', 'face', 'facebook', 'fact', 'fail',\n",
       "       'failed', 'fair', 'fall', 'fam', 'family', 'fan', 'fans',\n",
       "       'fantastic', 'far', 'fast', 'favorite', 'fb', 'feel', 'feelin',\n",
       "       'feeling', 'feels', 'feet', 'fell', 'felt', 'fever', 'ff',\n",
       "       'figure', 'film', 'final', 'finally', 'fine', 'fingers', 'finish',\n",
       "       'finished', 'fix', 'flight', 'flu', 'fly', 'fm', 'follow',\n",
       "       'followed', 'follower', 'followers', 'following', 'food', 'foot',\n",
       "       'forever', 'forget', 'forgot', 'forward', 'free', 'french',\n",
       "       'friday', 'friend', 'friends', 'fun', 'funny', 'game', 'games',\n",
       "       'garden', 'gave', 'gd', 'gets', 'gettin', 'getting', 'gift',\n",
       "       'girl', 'girls', 'giving', 'glad', 'god', 'goes', 'goin', 'going',\n",
       "       'gone', 'gonna', 'good', 'goodbye', 'goodnight', 'google',\n",
       "       'gorgeous', 'got', 'gotta', 'graduation', 'great', 'green',\n",
       "       'group', 'guess', 'guitar', 'gutted', 'guy', 'guys', 'gym', 'ha',\n",
       "       'haha', 'hahah', 'hahaha', 'hair', 'half', 'hand', 'hang',\n",
       "       'hanging', 'hannah', 'happen', 'happened', 'happens', 'happy',\n",
       "       'hard', 'hate', 'hates', 'haven', 'havent', 'having', 'head',\n",
       "       'headache', 'heading', 'hear', 'heard', 'heart', 'hehe', 'hell',\n",
       "       'hello', 'help', 'hey', 'hi', 'high', 'history', 'hit', 'hmm',\n",
       "       'hmmm', 'holiday', 'home', 'homework', 'hope', 'hopefully',\n",
       "       'hoping', 'horrible', 'hospital', 'hot', 'hour', 'hours', 'house',\n",
       "       'http', 'hubby', 'hug', 'huge', 'hugs', 'huh', 'hun', 'hungry',\n",
       "       'hurt', 'hurts', 'ice', 'id', 'idea', 'idk', 'ill', 'im', 'ima',\n",
       "       'imagine', 'inside', 'instead', 'interesting', 'internet',\n",
       "       'iphone', 'ipod', 'isn', 'isnt', 'itunes', 'ive', 'iï', 'jay',\n",
       "       'jealous', 'job', 'john', 'join', 'jonas', 'july', 'june', 'jus',\n",
       "       'just', 'justin', 'keeps', 'kid', 'kids', 'kill', 'kind', 'kinda',\n",
       "       'knew', 'know', 'la', 'lady', 'lame', 'laptop', 'late', 'later',\n",
       "       'laugh', 'lazy', 'learn', 'leave', 'leaving', 'left', 'legs',\n",
       "       'let', 'lets', 'life', 'like', 'liked', 'lil', 'line', 'link',\n",
       "       'list', 'listen', 'listening', 'little', 'live', 'living', 'll',\n",
       "       'lmao', 'lol', 'london', 'lonely', 'long', 'longer', 'look',\n",
       "       'looked', 'looking', 'looks', 'lost', 'lot', 'lots', 'love',\n",
       "       'loved', 'lovely', 'loves', 'loving', 'low', 'luck', 'lucky',\n",
       "       'lunch', 'luv', 'ly', 'ma', 'mac', 'mad', 'mail', 'make', 'makes',\n",
       "       'making', 'mama', 'man', 'mate', 'math', 'matter', 'maybe', 'mean',\n",
       "       'means', 'meant', 'meet', 'meeting', 'men', 'mention', 'message',\n",
       "       'messages', 'met', 'middle', 'miles', 'miley', 'min', 'mind',\n",
       "       'minute', 'minutes', 'miss', 'missed', 'missing', 'mobile', 'mom',\n",
       "       'moment', 'mommy', 'moms', 'monday', 'money', 'month', 'months',\n",
       "       'mood', 'moon', 'morning', 'mother', 'mothers', 'moved', 'movie',\n",
       "       'movies', 'moving', 'mr', 'mum', 'mums', 'music', 'myspace', 'nap',\n",
       "       'near', 'need', 'needed', 'needs', 'net', 'new', 'news', 'nice',\n",
       "       'night', 'nights', 'nite', 'non', 'nope', 'note', 'number', 'nyc',\n",
       "       'office', 'officially', 'oh', 'ohh', 'ok', 'okay', 'old', 'omg',\n",
       "       'ones', 'online', 'ooh', 'open', 'ouch', 'outside', 'packing',\n",
       "       'page', 'paid', 'pain', 'paper', 'parents', 'park', 'party',\n",
       "       'pass', 'past', 'pay', 'pc', 'people', 'perfect', 'person',\n",
       "       'phone', 'photo', 'photos', 'pic', 'pick', 'pics', 'picture',\n",
       "       'pictures', 'pizza', 'place', 'plan', 'plans', 'play', 'played',\n",
       "       'playing', 'plurk', 'plus', 'point', 'pool', 'poor', 'post',\n",
       "       'posted', 'power', 'ppl', 'pretty', 'prob', 'probably', 'problem',\n",
       "       'problems', 'profile', 'project', 'prom', 'proud', 'public',\n",
       "       'question', 'quick', 'quiet', 'quite', 'radio', 'rain', 'raining',\n",
       "       'rainy', 'ran', 'random', 'read', 'reading', 'ready', 'real',\n",
       "       'realized', 'really', 'reason', 'red', 'relaxing', 'remember',\n",
       "       'reply', 'rest', 'revision', 'ride', 'right', 'rock', 'room',\n",
       "       'round', 'run', 'running', 'sad', 'sadly', 'safe', 'said', 'sat',\n",
       "       'saturday', 'save', 'saw', 'say', 'saying', 'says', 'scared',\n",
       "       'scary', 'school', 'screen', 'season', 'second', 'seeing', 'seen',\n",
       "       'self', 'send', 'sending', 'sent', 'seriously', 'service', 'set',\n",
       "       'sexy', 'shall', 'shame', 'share', 'shes', 'shirt', 'shoes',\n",
       "       'shop', 'shopping', 'short', 'shot', 'shower', 'shows', 'sick',\n",
       "       'sigh', 'sign', 'sing', 'singing', 'single', 'sister', 'sit',\n",
       "       'site', 'sitting', 'sleep', 'sleeping', 'sleepy', 'slept', 'slow',\n",
       "       'small', 'smile', 'snl', 'sold', 'son', 'song', 'songs', 'soo',\n",
       "       'soon', 'sooo', 'soooo', 'sore', 'sorry', 'sound', 'sounds',\n",
       "       'special', 'spend', 'spent', 'star', 'starbucks', 'start',\n",
       "       'started', 'starting', 'starts', 'stay', 'staying', 'stomach',\n",
       "       'stop', 'stopped', 'store', 'story', 'stuck', 'study', 'studying',\n",
       "       'stuff', 'stupid', 'suck', 'sucks', 'summer', 'sun', 'sunday',\n",
       "       'sunny', 'sunshine', 'super', 'support', 'supposed', 'sure',\n",
       "       'sweet', 'swine', 'taken', 'takes', 'taking', 'talent', 'talk',\n",
       "       'talking', 'taylor', 'tea', 'team', 'tell', 'test', 'text',\n",
       "       'thank', 'thanks', 'thats', 'thing', 'things', 'think', 'thinking',\n",
       "       'thinks', 'tho', 'thought', 'throat', 'thursday', 'thx', 'ticket',\n",
       "       'tickets', 'til', 'till', 'time', 'times', 'tinyurl', 'tired',\n",
       "       'today', 'told', 'tom', 'tomorrow', 'tonight', 'tonite', 'took',\n",
       "       'totally', 'touch', 'tour', 'town', 'traffic', 'train', 'trek',\n",
       "       'tried', 'trip', 'true', 'try', 'trying', 'tuesday', 'tummy',\n",
       "       'turn', 'tv', 'tweet', 'tweeting', 'tweets', 'twilight', 'twitpic',\n",
       "       'twitter', 'ugh', 'uk', 'understand', 'unfortunately', 'update',\n",
       "       'updates', 'upset', 'ur', 'use', 'used', 'using', 'usually',\n",
       "       'vacation', 've', 'vegas', 'version', 'video', 'videos', 'visit',\n",
       "       'voice', 'vote', 'wait', 'waiting', 'wake', 'waking', 'walk',\n",
       "       'walking', 'wanna', 'want', 'wanted', 'wants', 'warm', 'wars',\n",
       "       'wasn', 'watch', 'watched', 'watching', 'water', 'way', 'wear',\n",
       "       'wearing', 'weather', 'web', 'website', 'wedding', 'week',\n",
       "       'weekend', 'weeks', 'weird', 'welcome', 'went', 'whats', 'white',\n",
       "       'wife', 'win', 'windows', 'wine', 'wish', 'wishes', 'wishing',\n",
       "       'woke', 'wolverine', 'won', 'wonder', 'wonderful', 'wondering',\n",
       "       'wont', 'woo', 'word', 'words', 'work', 'worked', 'working',\n",
       "       'works', 'world', 'worried', 'worry', 'worse', 'worst', 'worth',\n",
       "       'wouldn', 'wow', 'write', 'writing', 'wrong', 'wtf', 'www', 'xd',\n",
       "       'xoxo', 'ya', 'yay', 'yea', 'yeah', 'year', 'years', 'yep', 'yes',\n",
       "       'yesterday', 'young', 'youtube', 'yum', 'yummy', 'yup', '½m'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'responded,'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow280/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'responded,'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [92]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresponded,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow280/lib/python3.9/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow280/lib/python3.9/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'responded,'"
     ]
    }
   ],
   "source": [
    "data['responded,']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         neutral\n",
       "1        negative\n",
       "2        negative\n",
       "3        negative\n",
       "4        negative\n",
       "           ...   \n",
       "27476    negative\n",
       "27477    negative\n",
       "27478    positive\n",
       "27479    positive\n",
       "27480     neutral\n",
       "Name: sentiment, Length: 27480, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y = pd.get_dummies(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, data_y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21984, 926)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24567</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24619</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19766</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21737</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8980</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13124</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19649</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9846</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10800</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2733</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21984 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       negative  neutral  positive\n",
       "24567         0        1         0\n",
       "24619         1        0         0\n",
       "19766         0        0         1\n",
       "21737         0        0         1\n",
       "8980          0        1         0\n",
       "...         ...      ...       ...\n",
       "13124         0        0         1\n",
       "19649         0        1         0\n",
       "9846          0        1         0\n",
       "10800         0        0         1\n",
       "2733          0        1         0\n",
       "\n",
       "[21984 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21984, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Now let's make a simple neural network with 1 hidden layer containing 10 neurons\n",
    "num_neurons = 100 # neurons in each layer\n",
    "model = Sequential()\n",
    "\n",
    "#Make the first (hidden) layer, which will have num_neurons neurons. Each neuron will get inputs from all columns of the dataframe, except sentiment\n",
    "#model.add(Dense(num_neurons, input_dim=len(data.columns)-1))\n",
    "model.add(Dense(num_neurons, input_dim=np.shape(X_train)[1]))\n",
    "model.add(Activation('relu')) #Now we'll use a sigmoid activation function\n",
    "\n",
    "model.add(Dense(num_neurons))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#Now let's add another layer for the output: A single sigmoid neuron.\n",
    "model.add(Dense(3)) \n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_44 (Dense)            (None, 100)               92700     \n",
      "                                                                 \n",
      " activation_44 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_45 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 3)                 303       \n",
      "                                                                 \n",
      " activation_46 (Activation)  (None, 3)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 103,103\n",
      "Trainable params: 103,103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lfy/opt/anaconda3/envs/tensorflow280/lib/python3.9/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Use compile() to set up our training\n",
    "\n",
    "# For loss, we'll use binary cross-entropy loss, \n",
    "# which is appropriate for a binary classification problem (0/1 for negative/positive)\n",
    "# ***If you edit this notebook to apply it to a multi-class classification problem, you'll need \n",
    "#    to change the loss to something like categorical_crossentropy, and you'll also need to change the\n",
    "#    encoding of the class to a one hot representation (see https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/)\n",
    "\n",
    "opt = SGD(lr=0.01, momentum=0.9)\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 18/687 [..............................] - ETA: 4s - loss: 1.0939 - accuracy: 0.3698"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 22:14:59.727714: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "683/687 [============================>.] - ETA: 0s - loss: 0.9318 - accuracy: 0.5574"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 22:15:04.032164: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687/687 [==============================] - 5s 8ms/step - loss: 0.9316 - accuracy: 0.5575 - val_loss: 0.8283 - val_accuracy: 0.6403\n",
      "Epoch 2/20\n",
      "687/687 [==============================] - 5s 7ms/step - loss: 0.7628 - accuracy: 0.6801 - val_loss: 0.7650 - val_accuracy: 0.6763\n",
      "Epoch 3/20\n",
      "687/687 [==============================] - 5s 7ms/step - loss: 0.7210 - accuracy: 0.7048 - val_loss: 0.7506 - val_accuracy: 0.6900\n",
      "Epoch 4/20\n",
      "687/687 [==============================] - 5s 7ms/step - loss: 0.6925 - accuracy: 0.7172 - val_loss: 0.7588 - val_accuracy: 0.6869\n",
      "Epoch 5/20\n",
      "687/687 [==============================] - 5s 8ms/step - loss: 0.6663 - accuracy: 0.7277 - val_loss: 0.7508 - val_accuracy: 0.6930\n",
      "Epoch 6/20\n",
      "687/687 [==============================] - 5s 7ms/step - loss: 0.6449 - accuracy: 0.7397 - val_loss: 0.7621 - val_accuracy: 0.6865\n",
      "Epoch 7/20\n",
      "687/687 [==============================] - 5s 7ms/step - loss: 0.6212 - accuracy: 0.7524 - val_loss: 0.7840 - val_accuracy: 0.6679\n",
      "Epoch 8/20\n",
      "687/687 [==============================] - 5s 7ms/step - loss: 0.5920 - accuracy: 0.7620 - val_loss: 0.7805 - val_accuracy: 0.6798\n",
      "Epoch 9/20\n",
      "687/687 [==============================] - 5s 8ms/step - loss: 0.5615 - accuracy: 0.7774 - val_loss: 0.8258 - val_accuracy: 0.6805\n",
      "Epoch 10/20\n",
      "687/687 [==============================] - 5s 7ms/step - loss: 0.5278 - accuracy: 0.7943 - val_loss: 0.8391 - val_accuracy: 0.6645\n",
      "Epoch 11/20\n",
      "687/687 [==============================] - 5s 8ms/step - loss: 0.4907 - accuracy: 0.8084 - val_loss: 0.8840 - val_accuracy: 0.6699\n",
      "Epoch 12/20\n",
      "687/687 [==============================] - 5s 8ms/step - loss: 0.4480 - accuracy: 0.8285 - val_loss: 0.9284 - val_accuracy: 0.6590\n",
      "Epoch 13/20\n",
      "687/687 [==============================] - 5s 8ms/step - loss: 0.4190 - accuracy: 0.8390 - val_loss: 0.9763 - val_accuracy: 0.6559\n",
      "Epoch 14/20\n",
      "687/687 [==============================] - 5s 8ms/step - loss: 0.3788 - accuracy: 0.8548 - val_loss: 1.0567 - val_accuracy: 0.6299\n",
      "Epoch 15/20\n",
      "687/687 [==============================] - 5s 8ms/step - loss: 0.3547 - accuracy: 0.8673 - val_loss: 1.0767 - val_accuracy: 0.6472\n",
      "Epoch 16/20\n",
      "687/687 [==============================] - 5s 7ms/step - loss: 0.3205 - accuracy: 0.8802 - val_loss: 1.1742 - val_accuracy: 0.6447\n",
      "Epoch 17/20\n",
      "687/687 [==============================] - 5s 8ms/step - loss: 0.2991 - accuracy: 0.8883 - val_loss: 1.1921 - val_accuracy: 0.6476\n",
      "Epoch 18/20\n",
      "687/687 [==============================] - 5s 8ms/step - loss: 0.2835 - accuracy: 0.8949 - val_loss: 1.3003 - val_accuracy: 0.6372\n",
      "Epoch 19/20\n",
      "687/687 [==============================] - 5s 8ms/step - loss: 0.2596 - accuracy: 0.9056 - val_loss: 1.4128 - val_accuracy: 0.6392\n",
      "Epoch 20/20\n",
      "687/687 [==============================] - 5s 7ms/step - loss: 0.2365 - accuracy: 0.9131 - val_loss: 1.3855 - val_accuracy: 0.6406\n"
     ]
    }
   ],
   "source": [
    "#Train it!\n",
    "# Plus store history of training in a variable called \"history\"\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2ee977b80>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='training set accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'test set accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset  \n",
    "[Twitter Tweets Sentiment Dataset](https://www.kaggle.com/datasets/yasserh/twitter-tweets-sentiment-dataset)  \n",
    "\n",
    "## Changes  \n",
    "\n",
    "label: 0/1 -> one-hot representation  \n",
    "Final dense layer: 1 -> 3  \n",
    "Activation Function: Sigmoid -> Softmax  \n",
    "Loss Function: `binary_crossentropy` -> `categorical_crossentropy`. \n",
    "\n",
    "## Output  \n",
    "\n",
    "Train accuracy: 0.9131  \n",
    "Validation accuracy: 0.6406  \n",
    "\n",
    "## Evaluation  \n",
    "\n",
    "The model can't recognise synonyms in the input, and the dataset is not generalise enough for new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP Week 4.2-Neural network intro.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
